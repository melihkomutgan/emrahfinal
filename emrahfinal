head(cars)
nrow()
nrow(cars)
scatter.smooth(x = cars$speed, y = cars$dist, main = "Dist-Speed")
par(mfrow = c(1,2))

boxplot(cars$speed, main = "Speed", sub = paste("Outlier rows: ", boxplot.stats(cars$speed)$out)) #outlier değerler

boxplot.stats(cars$speed)$out  #outlier değerler 

boxplot(cars$dist, main = "Dist", sub = paste("Outlier rows:", boxplot.stats(cars$dist)$out)) #distance değerleri 120 outlier
#değer olarak görünür


#Normal dağılım gösterip göstermediğini anlamak için: density function grafiklerini çizdirmemiz gerekmektedir
# (yoğunluk fonksiyonlarının grafiklerini çizdirmemiz gerekir). 
#Bunu görmek için yine grafikleri yan yana çizdirmek daha akıllıca bir hamle olacaktır. 
#Bunun için tekrardan par() komutunu yazdırmak suretiyle bir pencerede iki adet grafik verecektir.
par(mfrow=c(1,2))

plot(density(cars$speed),
     main = "Density Plot: Speed", 
     ylab = "Frequency", 
     sub = paste("Skewness:", 
                 round(e1071::skewness(cars$speed), 2)))
#main → grafiğin adı,
#ylab → y eksenin adı,
#sub → grafiğin altına, “speed” değişkeninin çarpıklık dağılımını hesaplamak için 
round(e1071::skewness(cars$speed), 2)
#Burada “e1071” paketinden çağırıyoruz: “cars$speed” için skewness gerçekleştiriyoruz. 
#Ve burada “2” demek aslında yuvarla demektir; virgülden sonra 3-4 basamak varsa ikiye yuvarla demektir.

polygon(density(cars$speed), col = "red")

plot(density(cars$dist), 
     main = "Density Plot: Distance", 
     ylab = "Frequency", 
     sub = paste("Skewness:", 
                 round(e1071::skewness(cars$dist), 2)))

cor(cars$speed, cars$dist)
#0.8068949 speed ile distance arasında pozitif ve kuvvetli bir ilişki söz konusudur!

linearMod = lm(dist~speed, data=cars)
#Coefficients:
#(Intercept)        speed  
#-17.579        3.932  
# sabit terim -17 hız değişkeni 3.93
#doğrusal bir tahmin yapmak için kullanılır.
print(linearMod)

dist = -17.579 + 3.932  #doğrusal model budur.
dist
#-13.647

modelSummary = summary(linearMod)
modelSummary
#Estimate → katsayıların tahminleri
#Std. Error → katsayıların standart hataları
#t-value → katsayıların t değerleri
#Pr(>|t|) → t istatistiğinin olasılık değerleri
#Adjusted R-squared: → düzeltilmiş R-kare değeri
#F-statistic: → F istatistiği
#p-value: → F istatistiğinin olasılık değeri

Modelcoeffs = modelSummary$coefficients
#sadece katsayı tahminlerinlerini verir

beta.estimate = Modelcoeffs["speed", "Estimate"]
beta.estimate
#3.92 alfa= sabit terim beta=eğim katsayısı

std.error = Modelcoeffs["speed", "Std. Error"]
#0.41

t.value = beta.estimate/std.error #buradan t istatistik değerini bulmuş oluyoruz
t.value
#9.46

p_value = 2*pt(-abs(t.value), df=nrow(cars)-ncol(cars))
p_value
#1.489836e-12
#bu test çift yönlü olduğu için “2*pt” diyoruz.

ncol(cars)
#speed ve distance

p_value
#eğim katsayımız yani “speed”in önündeki katsayı 3.923 istatistiksel olarak ANLAMLIDIR.

hatalar = linearMod$residuals
hatalar
#hata terimlerini bulma

hatakaretop = sum(linearMod$residuals^2)
hatakaretop
#11353.52 hata kareler toplamını verir

modelstdhata = sqrt(hatakaretop/48)
modelstdhata
# 15.37959 model standart hatayı verir
##R2, korelasyonun karesidir.
y = cars$dist
print(y)
toplamdegiskenlik = ((y-mean(y))^2)
toplamdegiskenlik
#5932.0804 1765.6804
#R2, korelasyonun karesidir.

rkare = 1-(hatakaretop/toplamdegiskenlik)
print(rkare)
rkare
cor(cars)

summary(cars)$r.squared
cor(cars)
cor(cars)^2
VectorRSq = function(cars) {cor(cars)^2}
VectorRSq(cars)


###############################FAKTORİYEL HESAPLAMA DÖNGÜYLE#############################

number = as.integer(readline(prompt = "Lütfen bir sayı giriniz:"))
factorial = 1

if (number < 0) {
  print("Negatif sayıların faktöriyeli hesaplanamazdır!")
} else if (number == 0) {
  print("0 sayısının faktöriyeli 1'dir.")
} else {
  for(i in 1:number){
    factorial = factorial*i
  }
  print(paste("Girdiğiniz", number, "sayısının faktöriyeli", factorial, "sayısıdır."))
}


int <- as.integer(readline(prompt = "Please enter a number"))
facto <- 1

if (int < 0) {
  print("Negative numbers are not allowed")
} else if (int == 0) {
  print("The factorial of 0 is 1")
} else {
  facto <- factorial(int)
  print(facto)
}





#############################################################


#Basitçe bir regresyon analizi görmüş olduk. 
#Regresyon analizi nasıl yapılıyor? 
#Model nasıl tahmin ediliyor? 
#Katsayılar nasıl elde ediliyor? 
#Oradaki t-istatistikleri nasıl hesaplanılıyor? 
#Prob değeri nasıl hesaplanıyor? Veri seti ikiye nasıl bölünüyor 
#[trainingData ve testData olarak]? trainingData’dan nasıl parametreler tahminleniyor ve 
#testData ilişkin öngörümleme/tahmin yapıyoruz? 

head(cars)
linearMod = lm(dist~speed, data = cars)
lm(formula = dist ~ speed, data = cars)
linearMod
summary(linearMod)

#Burada hem katsayıların tahminleri hem standart hataları hem t-değerleri hem prob değerleri, 
#R2 değeri ve f-istatistiği vs. hepsi mevcuttur.

AIC(linearMod) #Akaike Bilgi Ölçütü (Akaike information criterion – AIC)
#419.1569

BIC(linearMod) #Bayesian information criterion – BIC
# 424.8929

set.seed(100)
#(öngörümleme = geleceği tahmin etmek [out of sample forecasting]). 

trainigRowIndex = sample(1:nrow(cars), 0.8*nrow(cars))
trainigRowIndex
trainingData = cars[trainigRowIndex,]
trainingData
testData = cars[-trainigRowIndex,]
testData


lmMod = lm(dist~speed, data = trainingData)
lmMod
#Coefficients:
#(Intercept)        speed  
#-20.237        4.135  


distPred = predict(lmMod, testData)
distPred
testData


#data.frame(cbind(actuals = dışarıda bıraktığımız 10 gözlemlik veri setindeki bağımlı değişkenler,
#predicteds = bağımlı değişkenimizin tahmini))

actual.preds = data.frame(cbind(actuals = testData$dist, predicteds = distPred))
actual.preds

cor(actual.preds)
actual.preds
#iki değişken arasında korelasyon incelenir ve yorumlanır

#0.83 yani %83’lık bir ilişki söz konusudur. 
#Gerçek değerler ile yapmış olduğumuz tahmin arasında %83’lık KUVVETLİ bir ilişki söz konusudur.


#ANOVA (VARYANS ANALİZİ)

head(PlantGrowth)
levels(PlantGrowth$group)
#"ctrl" "trt1" "trt2"

set.seed(1234)
dplyr::sample_n(PlantGrowth, 10)
levels(PlantGrowth$group)

#Bunları yazabilmek için öncelikle “dplyr” paketini indirip – aktive etmek gerekir!
group_by(PlantGrowth, group)%>%

summarise(count = n(), mean = mean(weight, na.rm=TRUE),
                                   sd = sd(weight, na.rm=TRUE))


#ggpubr install
ggboxplot(PlantGrowth, x = "group", y = "weight", color = "group", palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                     order = c("ctrl", "trt1", "trt2"), ylab = "Weight", xlab = "Treatment")

#ANOVA
res.aov = aov(weight~group, data = PlantGrowth)

aov(formula = weight ~ group, data = PlantGrowth)

summary(res.aov)

TukeyHSD(res.aov)

PlantGrowth

hist(PlantGrowth$weight, xlab = "Weight Value", main = "Histogram")

shapiro.test(PlantGrowth$weight)

data:  PlantGrowth$weight
mydata = PlantGrowth
boxplot(weight~group, data = mydata, ylab = "Weight", names = c("ctrl", "trt1", "trt2"))

mydata1 = subset(mydata, group == c("ctrl", "trt1"))
mydata2 = subset(mydata, group == c("ctrl", "trt2"))
mydata3 = subset(mydata, group == c("trt1", "trt2"))
t.test(weight~group, data = mydata1)


#H0: grup ortalamaları eşittir.
#H1: grup ortalamaları arasında en az biri diğerlerinden farklıdır.
#Buradan hareketler p değerim alfadan küçük olduğundan H0 RED, grup ortalamaları arasında en az biri diğerlerinden farklıdır.
t.test(weight~group, data = mydata1)
t.test(weight~group, data = mydata2)
t.test(weight~group, data = mydata3)

#tek yönlü ANOVA
anova(lm(weight~group, data = mydata))
df = data.frame(Exam, Sex, Degree)


#iki yönlü anova
anova(lm(Exam~Degree*Sex, data = df))

#kutu grafiği
boxplot(Exam~Degree+Sex, data = df, ylab = "Exam Scores", names = c("F Art", "F Joint", "F Sci", "M Art", "M Joint", "M Sci"))


#tapply her hücreye uygula
chick.means = tapply(chickwts$weight, INDEX = chickwts$feed, FUN = mean)
boxplot(chickwts$weight~chickwts$feed)
#1 den 6ya kadar değişkne kullanarak şekil verir
points(1:6, chick.means, pch = 4, cex = 1.5)


chick.sd = tapply(chickwts$weight, INDEX = chickwts$feed, FUN = sd)
chick.meancen = chickwts$weight - chick.means[as.numeric(chickwts$feed)]


deneme1 = chickwts$feed

deneme2 = as.numeric(chickwts$feed)

deneme3 = chick.means[as.numeric(chickwts$feed)]

chick.meancen = chickwts$weight - chick.means[as.numeric(chickwts$feed)]

#Neden hataları hesapladık? 
#Çünkü hataların normal dağılıp dağılmadığını gözlemlemek istiyoruz. Bunun için “qqplot” çizdireceğiz. Bunu çizdirebilmek için,

qqnorm(chick.meancen, main = "Normal QQ plot of residuals")

qqline(chick.meancen) #qqline doğrusunu çizebilmek için


chick.anova = aov(weight~feed, data = chickwts) #tek yönlü varyans analizi

#H0: Tavuk ağırlıklarının ortalamalarının eşit olduğu
#H1: Tavuk ağırlıklarının ortalamaları arasında en az bir tanesinin diğerlerinden farklı olduğu

tapply(warpbreaks$breaks, INDEX = list(warpbreaks$wool, warpbreaks$tension), FUN = mean)

wb.mean = aggregate(warpbreaks$breaks, by = list(warpbreaks$wool, warpbreaks$tension), FUN = mean)

summary(aov(breaks~wool + tension, data = warpbreaks))
#iki grup olduğunda two way anova yapılır 
summary(aov(breaks~wool + tension + wool:tension, data = warpbreaks))

interaction.plot(x.factor = wb.mean[,2], trace.factor = wb.mean[,1],
response = wb.mean$x,
trace.label = "wool",
xlab = "tension",
ylab = "mean wrap breaks")

library(MASS)
survey


age.means = tapply(survey$Age, survey$Smoke, mean)
age.means
age.meancen = survey$Age - age.means[as.numeric(survey$Smoke)] #ortalanmış ortalama


qqnorm(age.meancen, main = "Normal QQ plot of residuals")
qqline(age.meancen)

#normallik yok anova yapılmaz 
kruskal.test(Age~Smoke, data = survey)


plot(survey$Height~survey$Wr.Hnd, xlab = "Writing Handspan (cm)", ylab = "Height (cm)")
cor(survey$Wr.Hnd, survey$Height, use = "complete.obs") #x ile y arasındaki korelasyon

incomplete.obs = which(is.na(survey$Height)|is.na(survey$Wr.Hnd)) 

length(incomplete.obs)

survfit = lm(Height~Wr.Hnd, data = survey)

abline(survfit, lwd = 2) #y doğrusu çizer

obsA = c(survey$Wr.Hnd[197], survey$Height[197])

obsB = c(survey$Wr.Hnd[154], survey$Height[154])

names(survfit)

mycoef = coef(survfit) #katsayıları çıkartalım
mycoef
beta0 = mycoef[1] #sabit terim
beta1 = mycoef[2]

segments(x0 = c(obsA[1], obsB[1]), y0 = beta0 + beta1*c(obsA[1], obsB[1]), x1 = c(obsA[1], obsB[1]), y1 = c(obsA[2], obsB[2]), lty = 2)

summary(survfit)  
#Bu iki tane bağımsız değişken olduğundan basit regresyondur. Haliyle r-kareyi yorumlayabiliriz: 
#Kişini baş parmağı ile serçe parmağı arasındaki uzunluğu kullanarak kişinin boy uzunluğundaki değişimi açıklamak istiyorsam,  
#toplam değişimin ancak %36’sını açıklayabilirim.

#%95 güven aralığı ile sabit (intercept) için en düşük 103.225 ve en yüksek 124.68 olabiliyor.
#%95 güven aralığı ile eğim katsayısı (Wr.Hnd) için en düşük 2.547 ve en yüksek 3.685961 olabiliyor.

rh = cor(survey$Height, survey$Wr.Hnd, use = "complete.obs")
rh
rkare = rh^2
rkare

#Modelin hatalarının standart sapması ise,
summary(survfit)$sigma #standart hata



#y şapka = sabit terim + eğim katsayısı * (14.5)
as.numeric(beta0 + beta1*14.5)
as.numeric(beta0 + beta1*24)


xval = data.frame(Wr.Hnd = c(14.5, 24))
mypred = predict(survfit, newdata = xval, interval = "confidence", level = 0.95)
mypred


shapiro.test(PlantGrowth$weight)

data:  PlantGrowth$weight
mydata = PlantGrowth
boxplot(weight~group, data = mydata, ylab = "Weight", names = c("ctrl", "trt1", "trt2"))

mydata1 = subset(mydata, group == c("ctrl", "trt1"))
mydata2 = subset(mydata, group == c("ctrl", "trt2"))
mydata3 = subset(mydata, group == c("trt1", "trt2"))
t.test(weight~group, data = mydata1)


#H0: grup ortalamaları eşittir.
#H1: grup ortalamaları arasında en az biri diğerlerinden farklıdır.
#Buradan hareketler p değerim alfadan küçük olduğundan H0 RED, grup ortalamaları arasında en az biri diğerlerinden farklıdır.
t.test(weight~group, data = mydata1)
t.test(weight~group, data = mydata2)
t.test(weight~group, data = mydata3)

#tek yönlü ANOVA
anova(lm(weight~group, data = mydata))
df = data.frame(Exam, Sex, Degree)



